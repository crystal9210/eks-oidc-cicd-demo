# 障害報告書・事後レビュー（詳細サンプル）

## 1. インシデント基本情報

-   **インシデント ID**: INC20250629-001
-   **発生日時**: 2025-06-29 10:15 JST
-   **検知日時**: 2025-06-29 10:20 JST（Prometheus アラート自動検知）
-   **復旧日時**: 2025-06-29 11:05 JST
-   **報告日時**: 2025-06-29 11:10 JST
-   **報告者**: SRE 本部 田中一郎
-   **関係者**: CSIRT、SRE、DBA、開発、運用、経営層、外部委託先

## 2. 影響範囲・影響度（定量的評価）

-   **影響サービス**: 全 API（/v1/user, /v1/order, /v1/payment）
-   **影響ユーザー数**: 1,200,000 人中、同時接続最大 11,000 人
-   **影響時間**: 50 分
-   **障害発生件数**: 15,420 件（HTTP 5xx, DB 接続エラー）
-   **業務影響**: 決済遅延、ユーザー新規登録不可、管理画面ログイン不可
-   **外部通報要否**: 必要（取引先 2 社・監督官庁へ報告）

## 3. 障害発生の経緯（時系列・証跡付き）

| 時刻  | イベント内容                                   | 証跡・ログ                    |
| ----- | ---------------------------------------------- | ----------------------------- |
| 10:15 | DB 接続プール枯渇、API レイテンシ急増          | CloudWatch Alarm, Prometheus  |
| 10:17 | SRE 自動アラート Slack 通知                    | Slack #alert, Alertmanager    |
| 10:20 | SRE 一次対応開始、影響範囲調査                 | JIRA チケット INC20250629-001 |
| 10:25 | DB 接続数上限値超過を確認                      | RDS Insights, SlowQuery ログ  |
| 10:30 | DB 接続プール増強（max_connections: 500→1000） | RDS パラメータ変更ログ        |
| 10:35 | 一部復旧、API エラー率低下                     | Grafana ダッシュボード        |
| 10:50 | 全サービス正常化                               | CloudWatch, E2E テスト        |
| 11:05 | 影響ユーザーへのメール通知                     | SES ログ、顧客サポート履歴    |
| 11:10 | 事後レビュー会議招集                           | Google Calendar, Slack 通知   |

## 4. 原因分析（技術・プロセス・人的要因を分解）

### 4.1 技術的要因

-   **直接原因**:

    -   新規リリースで DB コネクションプールの最大値を 500→300 に誤設定（本来は 1,000 が必要）
    -   高トラフィック時にコネクション枯渇、アプリ側でリトライ多発 →DB 過負荷

-   **間接要因**:
    -   HPA/Auto Scaling が想定より遅延し、Pod 数不足
    -   DB パラメータ変更の CI/CD レビューが不十分

### 4.2 プロセス要因

-   DB パラメータ変更の事前検証・本番適用手順が明確化されていなかった
-   障害時のエスカレーションフローが一部メンバーに浸透していなかった

### 4.3 人的要因

-   レビュー担当者が DB 負荷試験の結果を十分に確認せず承認
-   障害発生時の初動連絡が 5 分遅延

## 5. 対応経緯・意思決定記録（根拠・証跡）

-   **10:20** SRE が JIRA でインシデント登録、CSIRT へ即時エスカレーション
-   **10:25** DB 負荷状況を RDS Insights で確認、max_connections 不足を特定
-   **10:30** DB パラメータ変更を緊急適用、監査証跡（CloudTrail）に記録
-   **10:35** API 復旧を確認、E2E テスト自動実行
-   **10:50** 監査部門・経営層へ報告、外部通報要否を法務と協議
-   **11:05** 顧客通知文面を法務・広報とレビューし送信

## 6. 再発防止策（具体施策・実装計画・担当・期限）

| 分類     | 施策内容                                      | 担当     | 期限 | 進捗管理        |
| -------- | --------------------------------------------- | -------- | ---- | --------------- |
| 技術     | DB コネクションプールの自動スケール導入       | SRE      | 7/15 | JIRA-1234       |
| 技術     | DB パラメータ変更用 CI/CD レビュー強化        | DevOps   | 7/10 | GitHub PR #456  |
| プロセス | 障害初動 Runbook の全員再教育・訓練           | 運用     | 7/20 | Confluence 更新 |
| プロセス | 変更管理フローの明文化・監査証跡強化          | PMO      | 7/31 | JIRA-1250       |
| 教育     | DB 負荷試験・パラメータ設計の定期トレーニング | 教育担当 | 8/10 | 研修資料公開    |

-   **進捗は週次でレビューし、未達時は経営層へ即時報告**

## 7. 添付証跡・データ（必須）

-   CloudWatch アラーム・メトリクスグラフ（障害発生前後の推移）
-   RDS Insights の接続数・遅延グラフ
-   JIRA/Confluence/Slack のタイムスタンプ付き記録
-   GitHub PR・CI/CD ログ・監査証跡（CloudTrail, Config）
-   顧客通知メール・サポート履歴

## 8. 教訓・組織的改善点

-   変更管理・レビュー・本番反映の全工程で自動監査・証跡化を徹底
-   障害初動 Runbook の定期訓練・教育を全員必須化
-   技術・プロセス・人的要因を分離して分析し、再発防止策を「実装・教育・運用」全方位で反映

## 9. フォーマット例（Markdown/Excel/Confluence）

-   すべての時系列・証跡・意思決定・添付資料を**時刻・根拠付きで記録**
-   進捗管理は JIRA や Confluence で「施策ごとに期限・責任者・レビュー履歴」を残す

**詳細かつ具体的な障害報告書・事後レビューをし、「証跡・判断根拠・再発防止策の実装計画・進捗管理」まで体系化します[1][2]。**

[1] preferences.information_presentation
[2] projects.requirement_management
